{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Government Measurement Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oxford Covid-19 Government Response Tracker (OxCGRT)\n",
    "oxcgrt_url = 'https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_latest.csv'\n",
    "oxcgrt_data = requests.get(oxcgrt_url).content\n",
    "oxcgrt_data = pd.read_csv(io.StringIO(oxcgrt_data.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Cases Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_url = 'https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/testing/covid-testing-all-observations.csv'\n",
    "test_data = requests.get(test_url).content\n",
    "test_data = pd.read_csv(io.StringIO(test_data.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirmed Cases Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_url = 'https://datahub.io/core/covid-19/r/time-series-19-covid-combined.csv'\n",
    "confirmed_data = requests.get(confirmed_url).content\n",
    "confirmed_data = pd.read_csv(io.StringIO(confirmed_data.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Due to different date format adopted by different dataset, we need to unify date format across different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxcgrt_data['Date'] = oxcgrt_data['Date'].apply(lambda x: pd.to_datetime(x, format='%Y%m%d'))\n",
    "test_data['Date'] = test_data['Date'].apply(lambda x: pd.to_datetime(x, format='%Y-%m-%d'))\n",
    "confirmed_data['Date'] = confirmed_data['Date'].apply(lambda x: pd.to_datetime(x, format='%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map from measurement name to its abbreviation and vice versa for government measure dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2m = {'S1': 'S1_School closing', 'S2': 'S2_Workplace closing', 'S3': 'S3_Cancel public events',\n",
    "       'S4': 'S4_Close public transport', 'S5': 'S5_Public information campaigns',\n",
    "       'S6': 'S6_Restrictions on internal movement', 'S7': 'S7_International travel controls'}\n",
    "m2a = {v: k for k, v in a2m.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Government measuers is divided into 13 indicators (S1 ~ S13), and we focus on S1 to S7,\n",
    "#### because S8 ~ S11 are fiscal and monetary policies and S12 ~ S13 are testing and contact tracing policies.\n",
    "#### A \"Stringency Index\" is also provided to measure the strigency of government measures.\n",
    "#### More descriptions can be found: https://www.bsg.ox.ac.uk/sites/default/files/2020-04/BSG-WP-2020-031-v4.0_0.pdf,\n",
    "#### and https://www.bsg.ox.ac.uk/sites/default/files/Calculation%20and%20presentation%20of%20the%20Stringency%20Index.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select S1 to S7 and Stringency Index\n",
    "dc_measure_data = dict()\n",
    "Measure = namedtuple('Measure', 'S1 S2, S3, S4, S5, S6, S7, stringency')\n",
    "for index, row in oxcgrt_data.iterrows():\n",
    "    value = []\n",
    "    for abbr, measure in a2m.items():\n",
    "        if np.isnan(row[measure]):\n",
    "            value.append(None)\n",
    "        else:\n",
    "            value.append(row[measure])\n",
    "    if np.isnan(row['StringencyIndexForDisplay']):\n",
    "        value.append(None)\n",
    "    else:\n",
    "        value.append(row['StringencyIndexForDisplay'])\n",
    "\n",
    "    key = (row['Date'], row['CountryName'])\n",
    "    value = Measure(*value)\n",
    "    dc_measure_data[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Due to incomplete reports by different governments, there are some invalid (NAN) values in the govrenment measurement dataset.\n",
    "#### We refill invalid values by the following steps:\n",
    "1. sort dictionary by keys which are tuples: first by country, second by date\n",
    "2. refill None values using the value of the before/after days, as measures won't change significantly\n",
    "3. delete a data sample if we cannot find a valid value in maximum 7 before/after days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_measure_data = {elem[0]: elem[1] for elem in sorted(dc_measure_data.items(), key=lambda x: (x[0][1], x[0][0]))}\n",
    "delete_key = []\n",
    "for key, value in dc_measure_data.items():\n",
    "    for s, v in value._asdict().items():\n",
    "        if v is None:\n",
    "            refill = False\n",
    "            # forward pass\n",
    "            cnt = 1\n",
    "            prev_date = key[0] + pd.DateOffset(-1)\n",
    "            prev_key = (prev_date, key[1])\n",
    "            while cnt < 7:\n",
    "                if dc_measure_data.get(prev_key, None) is not None:\n",
    "                    prev_v = getattr(dc_measure_data.get(prev_key, None), s)\n",
    "                    if prev_v is not None:\n",
    "                        dc_measure_data[key] = dc_measure_data[key]._replace(**{s: prev_v})\n",
    "                        refill = True\n",
    "                        break\n",
    "                    else:\n",
    "                        prev_date = prev_date + pd.DateOffset(-1)\n",
    "                        prev_key = (prev_date, key[1])\n",
    "                        cnt += 1\n",
    "                else:\n",
    "                    prev_date = prev_date + pd.DateOffset(-1)\n",
    "                    prev_key = (prev_date, key[1])\n",
    "                    cnt += 1\n",
    "            if not refill:\n",
    "                cnt = 1\n",
    "                after_date = key[0] + pd.DateOffset(1)\n",
    "                after_key = (after_date, key[1])\n",
    "                while cnt < 7:\n",
    "                    if dc_measure_data.get(after_key, None) is not None:\n",
    "                        after_v = getattr(dc_measure_data.get(after_key, None), s)\n",
    "                        if after_v is not None:\n",
    "                            dc_measure_data[key] = dc_measure_data[key]._replace(**{s: after_v})\n",
    "                            refill = True\n",
    "                            break\n",
    "                        else:\n",
    "                            after_date = after_date + pd.DateOffset(-1)\n",
    "                            after_key = (after_date, key[1])\n",
    "                            cnt += 1\n",
    "                    else:\n",
    "                        after_date = after_date + pd.DateOffset(-1)\n",
    "                        after_key = (after_date, key[1])\n",
    "                        cnt += 1\n",
    "                if not refill:\n",
    "                    delete_key.append(key)\n",
    "                    break\n",
    "\n",
    "dc_measure_data = {k: v for k, v in dc_measure_data.items() if k not in delete_key}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the test cases dataset, different countries report test numbers under one or more standards, including:\n",
    "#### 'tests performed', 'cases tested', 'people tested', ..., and 'unit unclear'.\n",
    "#### More information can be found: https://ourworldindata.org/covid-testing#our-checklist-for-covid-19-testing-data.\n",
    "#### To keep consistency, we only keep the test numbers under one standard which has the maximum available data samples.\n",
    "#### Note that as long as the standard in any single country is the same along the timeline, the analysis is valid.\n",
    "#### Steps are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: get the number of available data for each country under each standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_tested_dict = dict()     # 'sc' means standard and country\n",
    "for index, row in test_data.iterrows():\n",
    "    entity = row['Entity']\n",
    "    country, standard = entity.split('-')\n",
    "    country = country.strip()\n",
    "    standard = standard.strip()\n",
    "    if country not in sc_tested_dict.keys():\n",
    "        sc_tested_dict[country] = {standard: 1}\n",
    "    else:\n",
    "        if standard not in sc_tested_dict[country]:\n",
    "            sc_tested_dict[country][standard] = 1\n",
    "        else:\n",
    "            sc_tested_dict[country][standard] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: find the standard with the maximum number of availabel data for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc_tested_dict = dict()    # 'ssc' means single standard and country\n",
    "for country, value in sc_tested_dict.items():\n",
    "    sorted_value = {k: v for k, v in sorted(value.items(), key=lambda item: -item[1])}\n",
    "    standard = list(sorted_value)[0]\n",
    "    ssc_tested_dict[country] = standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: a). remove data that is not consistent with the selected standard; b). reformat Entity name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in test_data.iterrows():\n",
    "    entity = row['Entity']\n",
    "    country, standard = entity.split('-')\n",
    "    country = country.strip()\n",
    "    standard = standard.strip()\n",
    "    if standard != ssc_tested_dict[country]:\n",
    "        test_data.drop(index, inplace=True)\n",
    "    else:\n",
    "        test_data.loc[index, 'Entity'] = country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record the number of daily test cases using the number of cumulative cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_tested_dict = dict()\n",
    "Tested = namedtuple('Tested', 'cumulative daily')\n",
    "for index, row in test_data.iterrows():\n",
    "    key = (row['Date'], row['Entity'])\n",
    "    if not np.isnan(row['Daily change in cumulative total']):\n",
    "        dc_tested_dict[key] = Tested(int(row['Cumulative total']), int(row['Daily change in cumulative total']))\n",
    "    else:\n",
    "        dc_tested_dict[key] = Tested(int(row['Cumulative total']), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the confirmed cases dataset, the number of cummulative confirmed cases in some countries are inconsistent, and we need to:\n",
    "#### 1. Remove invalid (NaN) number of confirmed cases.\n",
    "#### 2. For some countries, combine all province/state statistics into a single country-level statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_confirmed_dict = dict()  # 'dc' means date and country\n",
    "for index, row in confirmed_data.iterrows():\n",
    "    key = (row['Date'], row['Country/Region'])\n",
    "    if not np.isnan(row['Confirmed']):\n",
    "        if key in dc_confirmed_dict.keys():\n",
    "            dc_confirmed_dict[key] = dc_confirmed_dict[key] + int(row['Confirmed'])\n",
    "        else:\n",
    "            dc_confirmed_dict[key] = int(row['Confirmed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compute daily confirmed cases using the number of cumulative cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Confirmed = namedtuple('Confirmed', 'cumulative daily')\n",
    "for key, value in dc_confirmed_dict.items():\n",
    "    prev_date_key = (key[0] + pd.DateOffset(-1), key[1])\n",
    "    if prev_date_key in dc_confirmed_dict.keys():\n",
    "        if not isinstance(dc_confirmed_dict[prev_date_key], Confirmed):\n",
    "            dc_confirmed_dict[key] = Confirmed(value, value - dc_confirmed_dict[prev_date_key])\n",
    "        else:\n",
    "            dc_confirmed_dict[key] = Confirmed(value, value - dc_confirmed_dict[prev_date_key].cumulative)\n",
    "    else:\n",
    "        dc_confirmed_dict[key] = Confirmed(value, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine data from three datasets together using dictionary structure: key - (date, country), value - (Measure, Confirmed, Tested).\n",
    "#### Because the three datasets are collected by different organizations/groups, we need to filter out incomplete data samples.\n",
    "#### Each item represent a sample for a country in a day which appears in all three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_combined_data = dict()   # 'dc' means date and country\n",
    "Combined = namedtuple('Combined', 'measure confirmed tested')\n",
    "for key, value in dc_measure_data.items():\n",
    "    if key in dc_confirmed_dict and key in dc_tested_dict:\n",
    "        dc_combined_data[key] = Combined(value, dc_confirmed_dict[key], dc_tested_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Have a look at the final combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 2547\n"
     ]
    }
   ],
   "source": [
    "print('Total number of samples: {}'.format(len(dc_combined_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A random sample in the integrated dataset:\n",
      "(Timestamp('2020-02-20 00:00:00'), 'South Africa')\n",
      "Combined(measure=Measure(S1=0.0, S2=0.0, S3=0.0, S4=0.0, S5=0.0, S6=0.0, S7=1.0, stringency=4.76), confirmed=Confirmed(cumulative=0, daily=0), tested=Tested(cumulative=106, daily=11))\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "key = random.choice(list(dc_combined_data.keys()))\n",
    "print('A random sample in the integrated dataset:')\n",
    "print(key)\n",
    "print(dc_combined_data[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
